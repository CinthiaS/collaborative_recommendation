{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e886eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f36de2",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d7e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_by_item(\n",
    "    df, users_df, items, rating_column='Rating', user_column='UserId', item_column='ItemId'):\n",
    "    \n",
    "    aux = df.loc[df[item_column].isin(items)]\n",
    "    aux = aux.pivot_table(index=user_column, columns=item_column, values=rating_column)\n",
    "    users_df = users_df.merge(aux, how='left', on=[user_column])\n",
    "    users_df = users_df.fillna('0')\n",
    "\n",
    "    return users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de813f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_by_users(\n",
    "    df, users, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Get items id evaluates by user target.\n",
    "\n",
    "    Args:\n",
    "      df: ps.DataFrame\n",
    "          predict rating value\n",
    "      user: str\n",
    "          user id\n",
    "      user_column: str, default UserId\n",
    "          name of column with users id\n",
    "      item_column: str, default ItemId\n",
    "      \n",
    "    Returns: \n",
    "    \n",
    "    list of strings with all items ids evaluated by user target\n",
    "    \"\"\"\n",
    "    \n",
    "    items = [list(df.loc[df[user_column] == user][item_column]) for user in users]\n",
    "    items = sorted(set(sum(items, [])))\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1ce05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_users_items(\n",
    "    df, item, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Get the ids of users that evaluate a item.\n",
    "\n",
    "    Args:\n",
    "      df: ps.DataFrame\n",
    "          predict rating value\n",
    "      item: str\n",
    "          item id\n",
    "      user_column: str, default UserId\n",
    "          name of column with users id\n",
    "      item_column: str, default ItemId\n",
    "          name of column with items id\n",
    "    Returns: \n",
    "    \n",
    "    list of strings with all users ids that evaluate a target item\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(df.loc[df[item_column] == item][user_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4ffbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "      x: np.array\n",
    "         vector of values\n",
    "      y: np.array\n",
    "         vector of valuesitem id\n",
    "         \n",
    "    Returns: \n",
    "    \n",
    "    cosine similarity between x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.dot(x, y)/(norm(x)*norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a01bf",
   "metadata": {},
   "source": [
    "# Item-based collaborative filtering\n",
    "\n",
    "Users who like an item tend to like similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93d2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(items):\n",
    "    \n",
    "    comb = []\n",
    "    k = 0\n",
    "    for i in items:\n",
    "        for j in range(1 + k, len(items)):\n",
    "            comb.append((i, items[j]))\n",
    "        k+=1\n",
    "\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df02b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_vector(item, users_df, ratings_df):\n",
    "    \n",
    "    aux = ratings_df.loc[ratings_df['ItemId'] == item][['UserId', 'Rating']]\n",
    "    df = users_df.merge(aux, how='left', on=['UserId']).fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca21ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_item_sim(comb, users_df, ratings_df):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(comb)):\n",
    "    \n",
    "        i1 = get_item_vector(comb[i][0], users_df, ratings_df)['Rating']\n",
    "        i2 = get_item_vector(comb[i][1], users_df, ratings_df)['Rating']\n",
    "\n",
    "        similarities.append(cosine_similarity(i1, i2))\n",
    "        \n",
    "    df = pd.DataFrame({\"items\": comb, \"similarity\": similarities})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a5d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_neighbors(item_sim, item_target, ratings_df):\n",
    "    \n",
    "    common_users = get_common_users_items(ratings_df, item=item_target)\n",
    "    \n",
    "    if common_users == []:\n",
    "        return None\n",
    "        \n",
    "    candidate_items = get_items_by_users(ratings_df, users=common_users)\n",
    "    \n",
    "    if candidate_items == []:\n",
    "        return None\n",
    "    \n",
    "    neighbors = item_sim[item_sim['items'].apply(lambda x: item_target in x)]\n",
    "    neighbors = neighbors.loc[neighbors['items'].apply(lambda x: any(candidate in x for candidate in candidate_items))]\n",
    "    neighbors = neighbors.reset_index(drop=True)\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a006be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate root mean squared error.\n",
    "\n",
    "    Args:\n",
    "      y_pred: float\n",
    "          predict rating value\n",
    "      y_true: float\n",
    "          true rating value\n",
    "    Returns: \n",
    "    \n",
    "    rmse: float\n",
    "        root mean squared error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0306442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute error.\n",
    "\n",
    "    Args:\n",
    "      y_pred: float\n",
    "          predict rating value\n",
    "      y_true: float\n",
    "          true rating value\n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    mae: float\n",
    "        mean absolute error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    return np.absolute(y_pred - y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667848c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, test_split=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset in train and test.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          ratings \n",
    "      test_split: float\n",
    "          percentage of data for the test dataset \n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    train: np.array\n",
    "        train dataset\n",
    "    test:\n",
    "        test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    size = int(X.shape[0])\n",
    "    all_indexes = list(range(size))\n",
    "                       \n",
    "    indexes_test = list(np.random.choice(np.arange(0,size), int(size*test_split), replace=False))\n",
    "    indexes_train = set(all_indexes) - set(indexes_test)\n",
    "    \n",
    "    train = X.loc[indexes_train].reset_index(drop=True)\n",
    "    test = X.loc[indexes_test].reset_index(drop=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fb5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(pred, max_pred=5, min_pred=1):\n",
    "    \"\"\"\n",
    "    Clip predict values in range [min_pred, max_pred].\n",
    "\n",
    "    Args:\n",
    "      pred : float\n",
    "          predict value\n",
    "      max_pred : int\n",
    "          max value of rating\n",
    "      min_pred : int\n",
    "          min value of rating\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pred: int\n",
    "        predict value cliped\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = max_pred if pred > max_pred else pred\n",
    "    pred = min_pred if pred < min_pred else pred\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7173c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, pu, qi, bu, bi, num_factors, mean, max_pred=5, min_pred=1):\n",
    "    \"\"\"\n",
    "    Predict rating for all pairs users items.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          rating matrix\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      num_factors: int\n",
    "          number of latent factors\n",
    "      mean: float\n",
    "          mean ratings of all users\n",
    "      max_pred: int\n",
    "          highest possible prediction\n",
    "      min_pred: int\n",
    "          lowest possible prediction\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    y_pred: np.array\n",
    "        predict values\n",
    "    y_true: np.array\n",
    "        targets values\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        \n",
    "        user, item, rui = X[idx, 0], X[idx, 1], X[idx, 2]\n",
    "\n",
    "        if (user > -1) and (item > -1):\n",
    "            pred = one_predict(pu, qi, bu, bi, user, item, num_factors, mean)\n",
    "            \n",
    "        pred = clip(pred, max_pred, min_pred)\n",
    "        \n",
    "        y_pred.append(pred)\n",
    "        y_true.append(rui)\n",
    "    \n",
    "    return np.asarray(y_pred), np.asarray(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd9190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(pu, qi, user, item, eui, num_factors, alpha=0.1, lamb=0.02):\n",
    "    \"\"\"\n",
    "    Update user and items matrix weights.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      eui: float\n",
    "          predict error\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix updated\n",
    "    qi: np.array\n",
    "          item matrix updated\n",
    "    \"\"\"\n",
    "    \n",
    "    for k in range(num_factors):\n",
    "        \n",
    "        puf = alpha * (eui * qi[k, item] - lamb * pu[user, k])\n",
    "        qif = alpha * (eui * pu[user, k] - lamb * qi[k, item]) \n",
    "        \n",
    "        pu[user, k] +=  puf\n",
    "        qi[k, item] +=  qif  \n",
    "        \n",
    "            \n",
    "    return pu, qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a7144f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bias(bu, bi, user, item, eui, alpha, lamb):\n",
    "    \"\"\"\"\n",
    "    Update bias weights.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      eui: float\n",
    "          predict error\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix updated\n",
    "    qi: np.array\n",
    "          item matrix updated\n",
    "    \"\"\"\n",
    "    \n",
    "    bu[user] += alpha * (eui * bu[user] - lamb * bi[item])\n",
    "    bi[item] += alpha * (eui * bi[item] - lamb * bi[item])\n",
    "    \n",
    "    return bu, bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c79a6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_predict(pu, qi, bu, bi, user, item, num_factors, mean):\n",
    "    \"\"\"\n",
    "    Predict rating to a pair user item.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      mean: float\n",
    "          mean ratings of all users\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    float: predicted value      \n",
    "    \"\"\"\n",
    "    \n",
    "    return sum([pu[user, k] * qi[k, item] for k in range(num_factors)]) + mean + bu[user] + bi[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb3fe8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialization(n, m, num_factors):\n",
    "    \"\"\"\n",
    "    Initialize weights.\n",
    "\n",
    "    Args:\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      num_factors: int\n",
    "          number of latent factors\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix random initialize\n",
    "    qi: np.array\n",
    "        item matrix random initialize\n",
    "    bu: np.array\n",
    "        bias vector for user weights initialize with zeros\n",
    "    bi: np.array\n",
    "        bias vector for item weights initialize with zeros\n",
    "    \"\"\"\n",
    "    \n",
    "    pu = np.random.rand(n, num_factors)\n",
    "    qi = np.random.rand(m, num_factors)\n",
    "    \n",
    "    bu = np.zeros(n)\n",
    "    bi = np.zeros(m)\n",
    "    \n",
    "    return pu, qi, bu, bi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c1940f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, alpha):\n",
    "    \"\"\"\n",
    "    Learning rating scheduler.\n",
    "    \n",
    "    Args:\n",
    "      epoch: int\n",
    "          actual epoch in training\n",
    "      alpha: int\n",
    "          learning rating\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    learning rate update \n",
    "    \"\"\"\n",
    "    \n",
    "    if epoch < 5:\n",
    "        return alpha\n",
    "    else:\n",
    "        return alpha * np.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f8ed063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(X, num_factors, n, m, mean, alpha=0.1, lamb=0.02):\n",
    "    \"\"\"\n",
    "    Stochastic Gradiend Descent.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          ratings data \n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix factored\n",
    "    qi: np.array\n",
    "        item matrix factored\n",
    "    bu: np.array\n",
    "        bias vector for user weights\n",
    "    bi: np.array\n",
    "        bias vector for item weights\n",
    "    \"\"\"\n",
    "    \n",
    "    pu, qi, bu, bi = inicialization(n, m, num_factors)\n",
    "    \n",
    "    qi = qi.T\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        \n",
    "        user, item, rui = X[idx, 0], X[idx, 1], X[idx, 2]\n",
    "        \n",
    "        #predict rating\n",
    "        pred = one_predict(pu, qi, bu, bi, user, item, num_factors, mean)\n",
    "        \n",
    "        #calculate error\n",
    "        eui = rui - pred\n",
    "        \n",
    "        #update bias\n",
    "        bu, bi = update_bias(bu, bi, user, item, eui, alpha, lamb)\n",
    "        \n",
    "        #Adjust weights\n",
    "        pu, qi = update_weights(pu, qi, user, item, eui, num_factors, alpha, lamb)\n",
    "        \n",
    "        \n",
    "    return pu, qi, bu, bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a7c9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X_train, num_factors, n, m, alpha=0.1, lamb=0.02, epochs=10, verbose=False):\n",
    "    \"\"\"\n",
    "    Fit Stochastic Gradiend Descent.\n",
    "\n",
    "    Args:\n",
    "      X_train: np.array\n",
    "          ratings data used to create the factored matrixes\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      alpha: float\n",
    "          learning rate\n",
    "      epochs: int\n",
    "          number of steps \n",
    "      verbose: boolean\n",
    "          if true, show all informations printed in functions\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix factored\n",
    "    qi: np.array\n",
    "        item matrix factored   \n",
    "    rmse: float\n",
    "        root mean squared error between predict rating values and true ratings values\n",
    "    mae: float\n",
    "        mean absolute error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    \n",
    "    mean = np.mean(X_train[:, 2])\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        alpha = scheduler(epoch, alpha)\n",
    "        \n",
    "        pu, qi, bu, bi = SGD(X_train, num_factors, n, m, mean, alpha=alpha, lamb=lamb)\n",
    "        \n",
    "        y_pred, y_true = predict(X_train, pu, qi, bu, bi, num_factors, mean)\n",
    "        \n",
    "        rmse = calc_rmse(y_pred, y_true)\n",
    "        mae = calc_mae(y_pred, y_true)\n",
    "        \n",
    "        if rmse < 0.01:\n",
    "            break\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"Epoch: {} - RMSE: {:.5f} - MAE: {:.5f}\".format(epoch, rmse, mae))\n",
    "            \n",
    "    return pu, qi, bu, bi, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f74486d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df (df, users, items, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Create a new rating dataframe where all users and itens are mapped for a continuous integer value\n",
    "    and.\n",
    "\n",
    "    Args:\n",
    "      df: pd.DataFrame\n",
    "          ratings_df\n",
    "      user: list\n",
    "          list with unique users code\n",
    "      items: str\n",
    "          list with unique items code\n",
    "      user_column: str, defaul UserId\n",
    "          column name of users\n",
    "      item_column: str, default ItemId\n",
    "          column name of items\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    df: pandas DataFrame with all users items ratings\n",
    "    dict_users: dictionary mapped users and your new code\n",
    "    dict_items: dictionary mapped items and your new code     \n",
    "    \"\"\"\n",
    "    \n",
    "    dict_users = dict(zip(users, range(len(users))))\n",
    "    dict_items = dict(zip(items, range(len(items))))\n",
    "\n",
    "    df[user_column] = df[user_column].map(dict_users)\n",
    "    df[item_column] = df[item_column].map(dict_items)\n",
    "\n",
    "    df = df.fillna(-1)\n",
    "    \n",
    "    return np.asarray(df), df, dict_users, dict_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6dc3fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_item_sim(comb, users_df, ratings_df, qi):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two pairs itens.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      mean: float\n",
    "          mean ratings of all users\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    float: predicted value      \n",
    "    \"\"\"\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(comb)):\n",
    "    \n",
    "        i1 = qi[dict_items.get(comb[i][0])]\n",
    "        i2 = qi[dict_items.get(comb[i][1])]\n",
    "\n",
    "        similarities.append(cosine_similarity(i1, i2))\n",
    "        \n",
    "    df = pd.DataFrame({\"items\": comb, \"similarity\": similarities})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eb2e552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_matrix_factorization(\n",
    "    num_factors=100, alpha=0.05, lamb=0.02, epochs=20,\n",
    "    user_column='UserId', item_column='ItemId', verbose=True):\n",
    "    \n",
    "    users = pd.unique(ratings_df[user_column]).tolist()\n",
    "    items = pd.unique(ratings_df[item_column]).tolist()\n",
    "\n",
    "    num_users = len(users)\n",
    "    num_items = len(items)\n",
    "\n",
    "    r, r_df, dict_users, dict_items = create_df (\n",
    "        ratings_df.copy(), users, items, user_column=user_column, item_column=item_column)\n",
    "\n",
    "    pu, qi, bu, bi, rmse, mae = fit(\n",
    "        r, num_factors=num_factors, n=num_users, m=num_items, alpha=alpha, lamb=lamb, epochs=epochs, verbose=True)\n",
    "    \n",
    "    return pu, qi, bu, bi, dict_users, dict_items, r_df, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cdc71916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_rating(row, pu, qi, bu, bi, user_mean):\n",
    "\n",
    "    user_target = dict_users.get(str(row[0]))\n",
    "    item_target = dict_items.get(str(row[1]))\n",
    "\n",
    "    pred = np.dot(qi[item_target], pu[user_target])\n",
    "    pred = clip(np.round(pred + user_mean + bu[user_target] + bi[item_target]))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ee64599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_ratings(\n",
    "    df, ratings_df, pu, qi, bu, bi, dict_users, dict_items,\n",
    "    n_neighboors, user_column, item_column, rating_column):\n",
    "  \n",
    "    user_mean = np.mean(ratings_df['Rating'])\n",
    "    \n",
    "    df['ui'] = list(zip(df[user_column], df[item_column]))\n",
    "    \n",
    "    vfunc = np.vectorize(predict_one_rating, excluded=['pu', 'qi', 'bu', 'bi', 'user_mean'])\n",
    "    \n",
    "    df[rating_column] = vfunc(row=df['ui'], pu=pu, qi=qi, bu=bu, bi=bi, user_mean=user_mean)\n",
    "    \n",
    "    return df[[user_column, item_column, rating_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - RMSE: 2.19264 - MAE: 1.55658\n",
      "Epoch: 1 - RMSE: 2.19668 - MAE: 1.56145\n",
      "Epoch: 2 - RMSE: 2.19037 - MAE: 1.55331\n",
      "Epoch: 3 - RMSE: 2.19558 - MAE: 1.56019\n",
      "Epoch: 4 - RMSE: 2.19140 - MAE: 1.55398\n",
      "Epoch: 5 - RMSE: 2.04673 - MAE: 1.41796\n",
      "Epoch: 6 - RMSE: 1.97192 - MAE: 1.34993\n",
      "Epoch: 7 - RMSE: 1.96954 - MAE: 1.35519\n",
      "Epoch: 8 - RMSE: 2.00407 - MAE: 1.40166\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "user_column = 'UserId'\n",
    "item_column = 'ItemId'\n",
    "rating_column = 'Rating'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "ratings['UserId:ItemId'] = ratings['UserId:ItemId'].str.split(':')\n",
    "ratings_df = pd.DataFrame(ratings['UserId:ItemId'].to_list(), columns=['UserId', 'ItemId'])\n",
    "ratings_df['Rating'] = ratings['Rating']\n",
    "\n",
    "targets = pd.read_csv(\"targets.csv\")\n",
    "targets['UserId:ItemId'] = targets['UserId:ItemId'].str.split(':')\n",
    "targets_df = pd.DataFrame(targets['UserId:ItemId'].to_list(), columns=['UserId', 'ItemId'])\n",
    "\n",
    "pu, qi, bu, bi, dict_users, dict_items, r_df, rmse, mae = main_matrix_factorization(num_factors=100, alpha=0.05, epochs=10)\n",
    "qi = qi.T\n",
    "\n",
    "result = predict_all_ratings(\n",
    "    targets_df, ratings_df, pu, qi, bu, bi, dict_users, dict_items,\n",
    "    n_neighboors, user_column, item_column, rating_column)\n",
    "\n",
    "result.to_csv(\"predict.csv\", index=False)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a94db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc083f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec15b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3e70e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd02152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8586e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6641f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5aefad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c52828f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to /scratch/cinthiasouza/.surprise_data/ml-100k\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9296  0.9371  0.9438  0.9356  0.9320  0.9356  0.0049  \n",
      "MAE (testset)     0.7346  0.7387  0.7440  0.7353  0.7349  0.7375  0.0036  \n",
      "Fit time          8.04    8.32    7.55    7.50    7.54    7.79    0.33    \n",
      "Test time         9.20    0.31    0.28    0.28    0.28    2.07    3.57    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92963382, 0.93709741, 0.94383365, 0.9355879 , 0.93198892]),\n",
       " 'test_mae': array([0.73459561, 0.73868008, 0.74398445, 0.73528318, 0.73489192]),\n",
       " 'fit_time': (8.041144609451294,\n",
       "  8.323009490966797,\n",
       "  7.553421258926392,\n",
       "  7.499321699142456,\n",
       "  7.544216632843018),\n",
       " 'test_time': (9.200531482696533,\n",
       "  0.30553770065307617,\n",
       "  0.2824246883392334,\n",
       "  0.2825336456298828,\n",
       "  0.27904582023620605)}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "710e2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ratings_by_user(\n",
    "   ratings_df, item_ratings, candidate_items, users, dict_users, dict_items,\n",
    "    user_target, user_column, item_column):\n",
    "    \n",
    "    pred_ratings = {}\n",
    "\n",
    "    for item in candidate_items:\n",
    "        \n",
    "        aux = {}\n",
    "        \n",
    "        for user in users:\n",
    "            \n",
    "            user_ratings = item_ratings.loc[item_ratings[user_column] == user]\n",
    "            user_mean = np.mean(ratings_df.loc[ratings_df[user_column] == user]['Rating'])\n",
    "          \n",
    "            rui = user_ratings.loc[user_ratings[item_column] == item]\n",
    "    \n",
    "            if not rui.empty:\n",
    "                aux[user] = int(rui['Rating'])\n",
    "            else:\n",
    "                aux[user] = clip(np.round(pu[dict_users.get(user)].dot(qi[dict_items.get(item)].T) + user_mean))\n",
    "\n",
    "        pred_ratings[item]= aux\n",
    "        \n",
    "    return pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "864437f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_user_target_ratings(\n",
    "    known_ratings, candidate_items, dict_users, dict_items, user_target, user_mean, item_column):\n",
    "    \n",
    "    pred_ratings = {}\n",
    "\n",
    "    for j in range(1, len(candidate_items)):\n",
    "    \n",
    "        x = known_ratings.loc[known_ratings[item_column] == candidate_items[j]]\n",
    "    \n",
    "        if not x.empty:\n",
    "            pred_ratings[candidate_items[j]] = int(x['Rating'])\n",
    "        else:\n",
    "            pred_ratings[candidate_items[j]] = clip(np.round(pu[dict_users.get(user_target)].dot(qi[dict_items.get(candidate_items[j])].T) + user_mean))\n",
    "        \n",
    "    return pred_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bb5aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_similarity():\n",
    "    \n",
    "    item_sim = {}\n",
    "    target = aux_item[0] -user_mean\n",
    "    \n",
    "    for j in range(1, len(candidate_items)):\n",
    "        \n",
    "        candidate = aux_item[0] - user_mean\n",
    "        \n",
    "    item_sim[candidate_items[j]] = cosine_similarity(aux_item[0], aux_item[j]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1977df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unknow_rating(user_target_ratings, item_sim, candidate_items):\n",
    "    \n",
    "    x = [np.dot(user_target_ratings[candidate_items[j]], item_sim[candidate_items[j]]) for j in range(1, len(candidate_items))]\n",
    "    d = [np.abs(i) for i in item_sim.values()]\n",
    "\n",
    "    pred = clip(np.round(sum(x)/sum(d)))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bc03064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(pred_ratings, item_target):\n",
    "\n",
    "    item_target_vector = np.asarray(list(pred_ratings[item_target].values()))\n",
    "\n",
    "    item_sim = {}\n",
    "\n",
    "    for key in  pred_ratings.keys():\n",
    "    \n",
    "        if key != item_target:\n",
    "            item_sim[key] =  cosine_similarity(item_target_vector, np.asarray(list(pred_ratings[key].values())))\n",
    "            \n",
    "    return item_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b984e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_predictv2(\n",
    "    aux, ratings_df, pu, qi, dict_users, dict_items,\n",
    "    n_neighboors, user_column, item_column):\n",
    "    \n",
    "  \n",
    "    results = {'user': [], 'item': [], 'pred': []}\n",
    "\n",
    "    for  idx, row in aux.iterrows():\n",
    "\n",
    "        user_target = row[user_column]\n",
    "        item_target = row[item_column]\n",
    "\n",
    "        results['user'].append(user_target)\n",
    "        results['item'].append(item_target)\n",
    "\n",
    "        common_users = get_common_users_items(ratings_df, item=item_target)\n",
    "\n",
    "        candidate_items = get_items_by_users(ratings_df, users=common_users)\n",
    "        candidate_items.remove(item_target)\n",
    "        candidate_items = candidate_items[:n_neighboors]\n",
    "        candidate_items.insert(0, item_target)\n",
    "\n",
    "        item_ratings = ratings_df.loc[ratings_df[item_column].isin(candidate_items)].reset_index(drop=True)\n",
    "        pred_ratings = fill_ratings_by_user(\n",
    "                ratings_df, item_ratings, candidate_items, common_users, dict_users,\n",
    "                dict_items, user_target, user_column, item_column)\n",
    "\n",
    "        item_sim = calculate_similarity(pred_ratings, item_target)\n",
    "\n",
    "        #item_sim = {candidate_items[j]: cosine_similarity(qi[dict_items.get(candidate_items[0])], qi[dict_items.get(candidate_items[j])]) for j in range(1, len(candidate_items))}\n",
    "\n",
    "        known_ratings = ratings_df.loc[ratings_df[user_column] == user_target].reset_index(drop=True)\n",
    "        user_mean = np.mean(ratings_df['Rating'])\n",
    "        user_target_ratings = fill_user_target_ratings(\n",
    "                known_ratings, candidate_items, dict_users, dict_items, user_target, user_mean, item_column)\n",
    "\n",
    "        try:\n",
    "            pred = calculate_unknow_rating(user_target_ratings, item_sim, candidate_items)\n",
    "            results['pred'].append(pred)\n",
    "            print(pred)\n",
    "        except ZeroDivisionError:\n",
    "            results['pred'].append(0)\n",
    "            \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "92f86a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d7f0f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ALS\n"
     ]
    }
   ],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = BaselineOnly(bsl_options=bsl_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "aebb8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3e4115fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(ratings_df, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "74f10660",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux20 = targets_df\n",
    "aux20['Ratings'] = [0]*(len(aux20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "40d214b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset.load_from_df(aux20, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "df9bf597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 1.1562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1561779894931252"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.1)\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "be25f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d30d71d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = [[i.uid, i.iid, i.r_ui] for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e11630f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.DataFrame(new_preds)\n",
    "aux = aux.rename(columns={0: user_column, 1: item_column, 2: \"Rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84905fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c4e5449f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 2 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Mean    Std     \n",
      "RMSE (testset)    1.1780  1.1749  1.1765  0.0015  \n",
      "MAE (testset)     0.8948  0.8943  0.8946  0.0003  \n",
      "Fit time          22.96   22.22   22.59   0.37    \n",
      "Test time         3.62    3.06    3.34    0.28    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.178034  , 1.17493987]),\n",
       " 'test_mae': array([0.89484386, 0.89431522]),\n",
       " 'fit_time': (22.964514017105103, 22.22034525871277),\n",
       " 'test_time': (3.6192076206207275, 3.0629162788391113)}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "db4b03fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatasetAutoFolds' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-96a332cff024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/surprise/prediction_algorithms/algo_base.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, testset, verbose)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m# The ratings are translated back to their original scale.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         predictions = [self.predict(uid,\n\u001b[0m\u001b[1;32m    165\u001b[0m                                     \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                                     \u001b[0mr_ui_trans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DatasetAutoFolds' object is not iterable"
     ]
    }
   ],
   "source": [
    "predictions = algo.test(data)\n",
    "accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "47d25d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommender.py\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "# To use item-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # Compute  similarities between items\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "264f1139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7fbbf9a56d00>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet = data.build_full_trainset()\n",
    "algo.fit(trainingSet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bf30461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.19"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = algo.predict('E', 2)\n",
    "prediction.est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "681a67d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='E', iid=2, r_ui=None, est=4.19, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
