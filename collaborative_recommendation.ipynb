{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e886eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f36de2",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d7e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_by_item(\n",
    "    df, users_df, items, rating_column='Rating', user_column='UserId', item_column='ItemId'):\n",
    "    \n",
    "    aux = df.loc[df[item_column].isin(items)]\n",
    "    aux = aux.pivot_table(index=user_column, columns=item_column, values=rating_column)\n",
    "    users_df = users_df.merge(aux, how='left', on=[user_column])\n",
    "    users_df = users_df.fillna('0')\n",
    "\n",
    "    return users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de813f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_by_users(\n",
    "    df, users, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Get items id evaluates by user target.\n",
    "\n",
    "    Args:\n",
    "      df: ps.DataFrame\n",
    "          predict rating value\n",
    "      user: str\n",
    "          user id\n",
    "      user_column: str, default UserId\n",
    "          name of column with users id\n",
    "      item_column: str, default ItemId\n",
    "      \n",
    "    Returns: \n",
    "    \n",
    "    list of strings with all items ids evaluated by user target\n",
    "    \"\"\"\n",
    "    \n",
    "    items = [list(df.loc[df[user_column] == user][item_column]) for user in users]\n",
    "    items = sorted(set(sum(items, [])))\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1ce05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_users_items(\n",
    "    df, item, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Get the ids of users that evaluate a item.\n",
    "\n",
    "    Args:\n",
    "      df: ps.DataFrame\n",
    "          predict rating value\n",
    "      item: str\n",
    "          item id\n",
    "      user_column: str, default UserId\n",
    "          name of column with users id\n",
    "      item_column: str, default ItemId\n",
    "          name of column with items id\n",
    "    Returns: \n",
    "    \n",
    "    list of strings with all users ids that evaluate a target item\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(df.loc[df[item_column] == item][user_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d4ffbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Calculates cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "      x: np.array\n",
    "         vector of values\n",
    "      y: np.array\n",
    "         vector of valuesitem id\n",
    "         \n",
    "    Returns: \n",
    "    \n",
    "    cosine similarity between x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.dot(x, y)/(norm(x)*norm(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a01bf",
   "metadata": {},
   "source": [
    "# Item-based collaborative filtering\n",
    "\n",
    "Users who like an item tend to like similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93d2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(items):\n",
    "    \n",
    "    comb = []\n",
    "    k = 0\n",
    "    for i in items:\n",
    "        for j in range(1 + k, len(items)):\n",
    "            comb.append((i, items[j]))\n",
    "        k+=1\n",
    "\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df02b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_vector(item, users_df, ratings_df):\n",
    "    \n",
    "    aux = ratings_df.loc[ratings_df['ItemId'] == item][['UserId', 'Rating']]\n",
    "    df = users_df.merge(aux, how='left', on=['UserId']).fillna(0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca21ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_item_sim(comb, users_df, ratings_df):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(comb)):\n",
    "    \n",
    "        i1 = get_item_vector(comb[i][0], users_df, ratings_df)['Rating']\n",
    "        i2 = get_item_vector(comb[i][1], users_df, ratings_df)['Rating']\n",
    "\n",
    "        similarities.append(cosine_similarity(i1, i2))\n",
    "        \n",
    "    df = pd.DataFrame({\"items\": comb, \"similarity\": similarities})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a5d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_neighbors(item_sim, item_target, ratings_df):\n",
    "    \n",
    "    common_users = get_common_users_items(ratings_df, item=item_target)\n",
    "    \n",
    "    if common_users == []:\n",
    "        return None\n",
    "        \n",
    "    candidate_items = get_items_by_users(ratings_df, users=common_users)\n",
    "    \n",
    "    if candidate_items == []:\n",
    "        return None\n",
    "    \n",
    "    neighbors = item_sim[item_sim['items'].apply(lambda x: item_target in x)]\n",
    "    neighbors = neighbors.loc[neighbors['items'].apply(lambda x: any(candidate in x for candidate in candidate_items))]\n",
    "    neighbors = neighbors.reset_index(drop=True)\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a006be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate root mean squared error.\n",
    "\n",
    "    Args:\n",
    "      y_pred: float\n",
    "          predict rating value\n",
    "      y_true: float\n",
    "          true rating value\n",
    "    Returns: \n",
    "    \n",
    "    rmse: float\n",
    "        root mean squared error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0306442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate mean absolute error.\n",
    "\n",
    "    Args:\n",
    "      y_pred: float\n",
    "          predict rating value\n",
    "      y_true: float\n",
    "          true rating value\n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    mae: float\n",
    "        mean absolute error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    return np.absolute(y_pred - y_true).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "667848c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, test_split=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset in train and test.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          ratings \n",
    "      test_split: float\n",
    "          percentage of data for the test dataset \n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    train: np.array\n",
    "        train dataset\n",
    "    test:\n",
    "        test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    size = int(X.shape[0])\n",
    "    all_indexes = list(range(size))\n",
    "                       \n",
    "    indexes_test = list(np.random.choice(np.arange(0,size), int(size*test_split), replace=False))\n",
    "    indexes_train = set(all_indexes) - set(indexes_test)\n",
    "    \n",
    "    train = X.loc[indexes_train].reset_index(drop=True)\n",
    "    test = X.loc[indexes_test].reset_index(drop=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fb5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(pred, max_pred=5, min_pred=1):\n",
    "    \"\"\"\n",
    "    Clip predict values in range [min_pred, max_pred].\n",
    "\n",
    "    Args:\n",
    "      pred : float\n",
    "          predict value\n",
    "      max_pred : int\n",
    "          max value of rating\n",
    "      min_pred : int\n",
    "          min value of rating\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pred: int\n",
    "        predict value cliped\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = max_pred if pred > max_pred else pred\n",
    "    pred = min_pred if pred < min_pred else pred\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fd9190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(\n",
    "    pu, qi, user, item, eui, num_factors, alpha=0.1, lamb=0.02):\n",
    "    \"\"\"\n",
    "    Update user and items matrix weights.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      eui: float\n",
    "          predict error\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix updated\n",
    "    qi: np.array\n",
    "          item matrix updated\n",
    "    \"\"\"\n",
    "    \n",
    "    for k in range(num_factors):\n",
    "        \n",
    "        puf = alpha * (eui * qi[k, item] - lamb * pu[user, k])\n",
    "        qif = alpha * (eui * pu[user, k] - lamb * qi[k, item]) \n",
    "        \n",
    "        pu[user, k] +=  puf\n",
    "        qi[k, item] +=  qif       \n",
    "            \n",
    "    return pu, qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7144f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bias(\n",
    "    bu, bi, user, item, eui, alpha, lamb):\n",
    "    \"\"\"\"\n",
    "    Update bias weights.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      eui: float\n",
    "          predict error\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix updated\n",
    "    qi: np.array\n",
    "          item matrix updated\n",
    "    \"\"\"\n",
    "    \n",
    "    bu[user] += alpha * (eui * bu[user] - lamb * bi[item])\n",
    "    bi[item] += alpha * (eui * bi[item] - lamb * bu[user])\n",
    "    \n",
    "    return bu, bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c79a6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_svd_predict(\n",
    "    pu, qi, bu, bi, user, item, num_factors, mean):\n",
    "    \"\"\"\n",
    "    Predict rating to a pair user item.\n",
    "\n",
    "    Args:\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      user: str\n",
    "          user code\n",
    "      item: str\n",
    "          item code\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      mean: float\n",
    "          mean ratings of all users\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    float: predicted value      \n",
    "    \"\"\"\n",
    "    \n",
    "    return sum([pu[user, k] * qi[k, item] for k in range(num_factors)]) + mean + bu[user] + bi[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7173c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_predict(\n",
    "    X, pu, qi, bu, bi, num_factors, mean_ratings, max_pred=5, min_pred=1):\n",
    "    \"\"\"\n",
    "    Predict rating for all pairs users items.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          rating matrix\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      num_factors: int\n",
    "          number of latent factors\n",
    "      mean: float\n",
    "          mean ratings of all users\n",
    "      max_pred: int\n",
    "          highest possible prediction\n",
    "      min_pred: int\n",
    "          lowest possible prediction\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    y_pred: np.array\n",
    "        predict values\n",
    "    y_true: np.array\n",
    "        targets values\n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        \n",
    "        user, item, rui = X[idx, 0], X[idx, 1], X[idx, 2]\n",
    "\n",
    "        mean = mean_ratings.get(item)\n",
    "\n",
    "        pred = one_svd_predict(pu, qi, bu, bi, user, item, num_factors, mean)\n",
    "        \n",
    "        y_pred.append(pred)\n",
    "        y_true.append(rui)\n",
    "    \n",
    "    return np.asarray(y_pred), np.asarray(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb3fe8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicialization(n, m, num_factors):\n",
    "    \"\"\"\n",
    "    Initialize weights.\n",
    "\n",
    "    Args:\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      num_factors: int\n",
    "          number of latent factors\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix random initialize\n",
    "    qi: np.array\n",
    "        item matrix random initialize\n",
    "    bu: np.array\n",
    "        bias vector for user weights initialize with zeros\n",
    "    bi: np.array\n",
    "        bias vector for item weights initialize with zeros\n",
    "    \"\"\"\n",
    "    \n",
    "    pu = np.random.normal(0, .1, (n, num_factors))\n",
    "    qi = np.random.normal(0, .1, (m, num_factors))\n",
    "    \n",
    "    bu = np.zeros(n)\n",
    "    bi = np.zeros(m)\n",
    "    \n",
    "    return pu, qi, bu, bi  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c1940f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, alpha):\n",
    "    \"\"\"\n",
    "    Learning rating scheduler.\n",
    "    \n",
    "    Args:\n",
    "      epoch: int\n",
    "          actual epoch in training\n",
    "      alpha: int\n",
    "          learning rating\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    learning rate update \n",
    "    \"\"\"\n",
    "    \n",
    "    if epoch < 2:\n",
    "        return alpha\n",
    "    else:\n",
    "        return 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f8ed063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(\n",
    "    X, num_factors, n, m, mean_ratings, alpha=0.001, lamb=0.002):\n",
    "    \"\"\"\n",
    "    Stochastic Gradiend Descent.\n",
    "\n",
    "    Args:\n",
    "      X: np.array\n",
    "          ratings data \n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      alpha: float\n",
    "          learning rate\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix factored\n",
    "    qi: np.array\n",
    "        item matrix factored\n",
    "    bu: np.array\n",
    "        bias vector for user weights\n",
    "    bi: np.array\n",
    "        bias vector for item weights\n",
    "    \"\"\"\n",
    "    \n",
    "    pu, qi, bu, bi = inicialization(n, m, num_factors)\n",
    "    \n",
    "    qi = qi.T\n",
    "    \n",
    "    for idx in range(X.shape[0]):\n",
    "        \n",
    "        user, item, rui = X[idx, 0], X[idx, 1], X[idx, 2]\n",
    "        \n",
    "        # get user mean ratings\n",
    "        mean = mean_ratings.get(item)\n",
    "\n",
    "        #predict rating\n",
    "        pred = one_svd_predict(pu, qi, bu, bi, user, item, num_factors, mean)\n",
    "        \n",
    "        #calculate error\n",
    "        eui = rui - pred\n",
    "        \n",
    "        #update bias\n",
    "        bu, bi = update_bias(bu, bi, user, item, eui, alpha, lamb)\n",
    "        \n",
    "        #Adjust weights\n",
    "        pu, qi = update_weights(pu, qi, user, item, eui, num_factors, alpha, lamb)\n",
    "        \n",
    "        \n",
    "    return pu, qi, bu, bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a7c9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    X_train, mean_ratings, num_factors, n, m, alpha=0.001, lamb=0.002, epochs=20, verbose=False):\n",
    "    \"\"\"\n",
    "    Fit Stochastic Gradiend Descent.\n",
    "\n",
    "    Args:\n",
    "      X_train: np.array\n",
    "          ratings data used to create the factored matrixes\n",
    "      num_factor: int\n",
    "          number of latent factors\n",
    "      n: int\n",
    "          number of unique users in ratings data\n",
    "      m: int\n",
    "          number of unique itens in ratings data\n",
    "      alpha: float\n",
    "          learning rate\n",
    "      epochs: int\n",
    "          number of steps \n",
    "      verbose: boolean\n",
    "          if true, show error values at all steps of training\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix factored\n",
    "    qi: np.array\n",
    "        item matrix factored\n",
    "    bu: np.array\n",
    "        fitted user bias vector\n",
    "    bi: np.array\n",
    "        fitted item bias vector\n",
    "    rmse: float\n",
    "        root mean squared error between predict rating values and true ratings values\n",
    "    mae: float\n",
    "        mean absolute error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #alpha = scheduler(epoch, alpha)\n",
    "        \n",
    "        pu, qi, bu, bi = SGD(X_train, num_factors, n, m, mean_ratings, alpha=alpha, lamb=lamb)\n",
    "        \n",
    "        y_pred, y_true = svd_predict(X_train, pu, qi, bu, bi, num_factors, mean_ratings)\n",
    "        \n",
    "        rmse = calc_rmse(y_pred, y_true)\n",
    "        mae = calc_mae(y_pred, y_true)\n",
    "        \n",
    "        if rmse < 0.01:\n",
    "            break\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"Epoch: {} - RMSE: {:.5f} - MAE: {:.5f}\".format(epoch, rmse, mae))\n",
    "            \n",
    "    return pu, qi, bu, bi, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f74486d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df (df, users, items, user_column='UserId', item_column='ItemId'):\n",
    "    \"\"\"\n",
    "    Create a new rating dataframe where all users and itens are mapped for a continuous integer value\n",
    "    and.\n",
    "\n",
    "    Args:\n",
    "      df: pd.DataFrame\n",
    "          ratings_df\n",
    "      user: list\n",
    "          list with unique users code\n",
    "      items: str\n",
    "          list with unique items code\n",
    "      user_column: str, defaul UserId\n",
    "          column name of users\n",
    "      item_column: str, default ItemId\n",
    "          column name of items\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    df: \n",
    "        pandas DataFrame with all users items ratings\n",
    "    dict_users: \n",
    "        dictionary mapped users and your new code\n",
    "    dict_items: \n",
    "        dictionary mapped items and your new code     \n",
    "    \"\"\"\n",
    "    \n",
    "    dict_users = dict(zip(users, range(len(users))))\n",
    "    dict_items = dict(zip(items, range(len(items))))\n",
    "\n",
    "    df[user_column] = df[user_column].map(dict_users)\n",
    "    df[item_column] = df[item_column].map(dict_items)\n",
    "\n",
    "    df = df.fillna(-1)\n",
    "    \n",
    "    return np.asarray(df), df, dict_users, dict_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93b7a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_ratings(df, dict_ratings, agg_metric='mean', agg_by='ItemId', rating_column='Rating'):\n",
    "    \n",
    "    grouped_ratings = df.groupby(agg_by)\n",
    "    \n",
    "    if agg_metric == \"mean\":\n",
    "        mean_ratings = grouped_ratings.mean().reset_index()\n",
    "    elif agg_metric == \"median\":\n",
    "        mean_ratings = grouped_ratings.mean().reset_index()\n",
    "        \n",
    "    mean_ratings[agg_by] = mean_ratings[agg_by].map(dict_ratings)\n",
    "    \n",
    "    dict_mean_ratings = dict(zip(mean_ratings[agg_by], mean_ratings[rating_column]))\n",
    "    \n",
    "    return mean_ratings, dict_mean_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb2e552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_matrix_factorization(\n",
    "    train_df, num_factors=100, alpha=0.001, lamb=0.002, epochs=20,\n",
    "    agg_metric='mean', agg_by='ItemId',\n",
    "    user_column='UserId', item_column='ItemId', rating_column='Rating', verbose=False):\n",
    "    \"\"\"\n",
    "        1. Format df\n",
    "        2. Matrix Factorization\n",
    "\n",
    "    Args:\n",
    "      X_train: np.array\n",
    "          ratings data used to create the factored matrixes\n",
    "      num_factors: int\n",
    "          number of latent factors\n",
    "      alpha: float\n",
    "          learning rate\n",
    "      lamb: float\n",
    "          regularization factor\n",
    "      epochs: int\n",
    "          number of steps \n",
    "      user_column: str, defaul UserId\n",
    "          column name of users\n",
    "      item_column: str, default ItemId\n",
    "          column name of items\n",
    "      verbose: boolean, default False\n",
    "          if true, show all steps\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pu: np.array\n",
    "        user matrix factored\n",
    "    qi: np.array\n",
    "        item matrix factored\n",
    "    bu: np.array\n",
    "        user bias vector\n",
    "    bi: np.array\n",
    "        item bias vector\n",
    "    dict_users: \n",
    "        dictionary mapped users and your new code\n",
    "    dict_items: \n",
    "        dictionary mapped items and your new code \n",
    "    r_df: pd.DataFrame\n",
    "        Format data\n",
    "    rmse: float\n",
    "        root mean squared error between predict rating values and true ratings values\n",
    "    mae: float\n",
    "        mean absolute error between predict rating values and true ratings values\n",
    "    \"\"\"\n",
    "    \n",
    "    users = pd.unique(train_df[user_column]).tolist()\n",
    "    items = pd.unique(train_df[item_column]).tolist()\n",
    "\n",
    "    num_users = len(users)\n",
    "    num_items = len(items)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\tFormatting data\")\n",
    "        \n",
    "    r, r_df, dict_users, dict_items = create_df (\n",
    "        train_df.copy(), users, items, user_column=user_column, item_column=item_column)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\tAggregating ratings\")\n",
    "        \n",
    "    _, dict_mean_ratings = agg_ratings(\n",
    "        train_df, dict_items, agg_metric=agg_metric, agg_by=agg_by, rating_column=rating_column)\n",
    "      \n",
    "    if verbose:\n",
    "        print(\"\\tFit SVD... Please waiting...\\n\")\n",
    "        \n",
    "    pu, qi, bu, bi, rmse, mae = fit(\n",
    "        r, mean_ratings=dict_mean_ratings, num_factors=num_factors, n=num_users,\n",
    "        m=num_items, alpha=alpha, lamb=lamb, epochs=epochs, verbose=verbose)\n",
    "    \n",
    "    return pu, qi, bu, bi, dict_users, dict_items, dict_mean_ratings, r_df, rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdc71916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_rating(row, pu, qi, bu, bi, dict_users, dict_items, mean_ratings, agg_by=\"item\"):\n",
    "    \"\"\"\n",
    "    Predict rating for a pair user-item\n",
    "\n",
    "    Args:\n",
    "      row: pd.Series\n",
    "          line of pandas df\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      bu: np.array\n",
    "          user bias vector\n",
    "      bi: np.array\n",
    "          item bias vector\n",
    "      user_mean: float\n",
    "          mean ratings of all users\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    pred: float\n",
    "        predicted value      \n",
    "    \"\"\"\n",
    "    \n",
    "    user_target = dict_users.get(str(row[0]))\n",
    "    item_target = dict_items.get(str(row[1]))\n",
    "    \n",
    "    if agg_by == 'item':\n",
    "        user_mean = mean_ratings.get(item_target)\n",
    "    elif agg_by == 'user':\n",
    "        user_mean = mean_ratings.get(user_target)\n",
    "        \n",
    "    pred = np.dot(pu[user_target], qi[item_target])\n",
    "    pred = clip(pred + user_mean + bu[user_target] + bi[item_target])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ee64599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_ratings(\n",
    "    test,  mean_ratings, pu, qi, bu, bi, dict_users, dict_items,\n",
    "    user_column='UserId', item_column='ItemId', rating_column='Rating', agg_by=\"item\"):\n",
    "    \"\"\"\n",
    "    Predict ratings for all pair user-item in dataframe.\n",
    "\n",
    "    Args:\n",
    "      test: pd.DataFrame, columns default, [UserId, ItemId]\n",
    "          train data\n",
    "      user_mean: float\n",
    "          mean ratings of all users\n",
    "      train: pd.DataFrame, columns default, [UserId, ItemId, Ratings]\n",
    "          train data\n",
    "      pu: np.array\n",
    "          user matrix\n",
    "      qi: np.array\n",
    "          item matrix\n",
    "      bu: np.array\n",
    "          user bias vector\n",
    "      bi: np.array\n",
    "          item bias vector\n",
    "      dict_users: float\n",
    "          mean ratings of all users\n",
    "      dict_users: float\n",
    "          mean ratings of all users\n",
    "      user_column: str, defaul UserId\n",
    "          column name of users\n",
    "      item_column: str, default ItemId\n",
    "          column name of items\n",
    "\n",
    "    Returns: \n",
    "\n",
    "    DataFrame with all predict values     \n",
    "    \"\"\"\n",
    "    \n",
    "    test['ui'] = list(zip(test[user_column], test[item_column]))\n",
    "    \n",
    "    vfunc = np.vectorize(\n",
    "        predict_one_rating,\n",
    "        excluded=['pu', 'qi', 'bu', 'bi', 'dict_users', 'dict_items', 'mean_ratings', 'agg_by'])\n",
    "    \n",
    "    test[rating_column] = vfunc(\n",
    "        row=test['ui'], pu=pu, qi=qi, bu=bu, bi=bi, dict_users=dict_users,\n",
    "        dict_items=dict_items, mean_ratings=mean_ratings, agg_by=agg_by)\n",
    "    \n",
    "    return test[[user_column, item_column, rating_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99a1f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_(x):\n",
    "    \n",
    "    return int(x + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62dae3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_and_save(\n",
    "    result, name_file='out.csv', user_column='UserId', item_column='ItemId',\n",
    "    rating_column='Rating', round_preds=False):\n",
    "    \n",
    "    if round_preds:\n",
    "        result[rating_column] = result[rating_column].apply(round_)\n",
    "    else:\n",
    "        result[rating_column] = result[rating_column]\n",
    "        \n",
    "    result[item_column] = result[item_column] + \",\" + result[rating_column].astype(str)\n",
    "    my_numpy = result[[user_column, item_column]].to_numpy()\n",
    "    np.savetxt(name_file, my_numpy, fmt='%s', delimiter=':', header='UserId:ItemId,Rating')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db7a289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(name_train='ratings', name_test='targets', user_column='UserId',\n",
    "         item_column='ItemId', rating_column='Rating', path_to_read='data', verbose=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    columns = '{}:{}'.format(user_column, item_column)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Read datasets\")\n",
    "        \n",
    "    train = pd.read_csv(\"{}/{}.csv\".format(path_to_read, name_train))\n",
    "    train[columns] = train[columns].str.split(':')\n",
    "    train_df = pd.DataFrame(train[columns].to_list(), columns=[user_column, item_column])\n",
    "    train_df[rating_column] = train[rating_column]\n",
    "\n",
    "    test = pd.read_csv(\"{}/{}.csv\".format(path_to_read, name_test))\n",
    "    test[columns] = test[columns].str.split(':')\n",
    "    test_df = pd.DataFrame(test[columns].to_list(), columns=[user_column, item_column])\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Matrix Factorization\")\n",
    "        \n",
    "    pu, qi, bu, bi, dict_users, dict_items, dict_mean_ratings, r_df, rmse, mae = main_matrix_factorization(\n",
    "        train_df, num_factors=15, alpha=0.001, epochs=3, verbose=verbose)\n",
    "    qi = qi.T\n",
    "    \n",
    "    if verbose: \n",
    "        print(\"Predict Ratings\")\n",
    "        \n",
    "    predictions = predict_all_ratings(\n",
    "        test_df, dict_mean_ratings, pu, qi, bu, bi, dict_users=dict_users,\n",
    "        dict_items=dict_items, user_column=user_column, item_column=item_column, rating_column=rating_column)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Save Results\")\n",
    "        \n",
    "    format_and_save(predictions)\n",
    "    \n",
    "    elapsed_time = (time.time() - start_time)/60\n",
    "    print(\"Time executioon: {} minutes\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f535b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read datasets\n",
      "Matrix Factorization\n",
      "\tFormatting data\n",
      "\tAggregating ratings\n",
      "\tFit SVD... Please waiting...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
